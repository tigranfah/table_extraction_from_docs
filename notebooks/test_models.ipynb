{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/cseadmin/Tigran/table_extractor/notebooks/../scripts/utils.py'>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, \"../scripts/\")\n",
    "\n",
    "from utils import train_test_split, image_batch_generator, get_train_augmentation, random_batch_generator, get_table_augmentation\n",
    "from utils import DATASET_PATH, DS_IMAGES, DS_MASKS, SaveValidSamplesCallback\n",
    "import utils\n",
    "from metrics import iou, f1_score, jaccard_distance\n",
    "import metrics\n",
    "from vis import anshow, imshow\n",
    "import vis\n",
    "from models import TableNet, load_unet_model\n",
    "\n",
    "IMAGE_NAMES = os.listdir(DS_IMAGES)\n",
    "\n",
    "import importlib\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(vis)\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 14:38:38.190246: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-01 14:38:38.990090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9237 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "model = load_unet_model((512, 512), 2, weight_decay=0.1)\n",
    "optim = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint training_checkpoints/2022.07.30-22/ckpt-238\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optim, net=model)\n",
    "print(f\"loading checkpoint {'training_checkpoints/' + '2022.07.30-22/' + 'ckpt-238'}\")\n",
    "status = checkpoint.restore(\"../scripts/training_checkpoints/\" + '2022.07.30-22/' + 'ckpt-238')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = jaccard_distance\n",
    "\n",
    "train_names, valid_names = train_test_split(IMAGE_NAMES, shuffle=True, random_state=2022, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batch_generator = image_batch_generator(\n",
    "                            valid_names, \n",
    "                            batch_size=8, \n",
    "                            resize_shape=(512, 512),\n",
    "                            aug_transform=None,\n",
    "                            normalize=True, include_edges_as_band=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(name, metrics, step, all_steps):\n",
    "    str_prog = f\"{all_steps}/{step}: \"\n",
    "    str_prog += \"{} loss {:.4f}, IOU {:.4f}, f1 {:.4f}, prec {:.4f}, rec {:.4f}\".format(\n",
    "        name,\n",
    "        np.mean(metrics[\"loss\"]), \n",
    "        np.mean(metrics[\"iou\"]), \n",
    "        np.mean(metrics[\"f1\"]),\n",
    "        np.mean(metrics[\"precision\"]),\n",
    "        np.mean(metrics[\"recall\"])\n",
    "    )\n",
    "\n",
    "    print(str_prog, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105: valid loss 9.1748, IOU 0.5016, f1 0.7208, prec 0.5476, rec 0.5883\r"
     ]
    }
   ],
   "source": [
    "val_metrics = {n:[] for n in (\"loss\", \"iou\", \"f1\", \"precision\", \"recall\")}\n",
    "\n",
    "mean_time = []\n",
    "\n",
    "# valid loop\n",
    "# with tf.device(\"GPU:0\"):\n",
    "\n",
    "for i, (batch_X, batch_y) in enumerate(valid_batch_generator):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # print(batch_X.dtype, batch_y.dtype)\n",
    "    # print(batch_y.min(), batch_y.max())\n",
    "    batch_X = tf.convert_to_tensor(batch_X, dtype=tf.float32)\n",
    "    batch_y = tf.convert_to_tensor(batch_y, dtype=tf.float32)\n",
    "\n",
    "    logits = model(batch_X, training=False)\n",
    "    logits = tf.squeeze(logits)\n",
    "\n",
    "    rgb_masks = np.array(logits * 255, dtype=np.uint8)\n",
    "    final_masks = []\n",
    "\n",
    "    for mask in rgb_masks:\n",
    "\n",
    "        thresh = thresh = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "        contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        final_mask = np.zeros_like(mask)\n",
    "\n",
    "        for ind, c in enumerate(contours):\n",
    "            if len(c) > 100:\n",
    "                min_x, max_x = np.squeeze(c)[:, 0].min(), np.squeeze(c)[:, 0].max()\n",
    "                min_y, max_y = np.squeeze(c)[:, 1].min(), np.squeeze(c)[:, 1].max()\n",
    "                final_mask[min_y:max_y, min_x:max_x] = 255\n",
    "\n",
    "        final_masks.append(final_mask / 255)\n",
    "\n",
    "    final_masks = tf.convert_to_tensor(final_masks, np.float32)\n",
    "\n",
    "    # print(np.unique(final_masks))\n",
    "\n",
    "    # print([metrics.iou(gt, pr) for gt, pr in zip(batch_y, final_masks)])\n",
    "    # break\n",
    "\n",
    "    loss_value = loss_fn(batch_y, final_masks)\n",
    "    # print(loss_value)\n",
    "\n",
    "    (\n",
    "        iou_value, f1_score_value, \n",
    "        presicion_value, \n",
    "        recall_value\n",
    "    ) = metrics.calculate_metrics(batch_y, final_masks)\n",
    "    val_metrics[\"loss\"].append(np.mean(loss_value))\n",
    "    val_metrics[\"iou\"].append(iou_value)\n",
    "    val_metrics[\"f1\"].append(f1_score_value)\n",
    "    val_metrics[\"precision\"].append(presicion_value)\n",
    "    val_metrics[\"recall\"].append(recall_value)\n",
    "\n",
    "    # break\n",
    "\n",
    "    mean_time.append(time.time() - start)\n",
    "    # print(f\"{len(valid_names)//8}/{i+1}\", end='\\r')\n",
    "    print_progress(\"valid\", val_metrics, i+1, len(valid_names)//8)\n",
    "    # break\n",
    "    if (i + 1) >= len(valid_names)//8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = {n:[] for n in (\"loss\", \"iou\", \"f1\", \"precision\", \"recall\")}\n",
    "mean_time = []\n",
    "\n",
    "batch_X, batch_y = utils.read_inf_sample(valid_names[:10], (512, 512))\n",
    "for i, (X, y) in enumerate(zip(batch_X, batch_y)):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    raw = model(tf.expand_dims(X, 0), training=False)\n",
    "    raw = tf.squeeze(raw)\n",
    "\n",
    "    pred = utils.preprocess_raw_output(raw, 2, 100 * 10)\n",
    "    # pred = utils.preprocess_raw_output(raw, 5, 1000 * 10)\n",
    "\n",
    "    mean_time.append(time.time() - start)\n",
    "\n",
    "    loss_value = loss_fn(y, pred)\n",
    "    (\n",
    "        iou_value, f1_score_value,\n",
    "        presicion_value, \n",
    "        recall_value\n",
    "    ) = metrics.calculate_metrics([y], [pred])\n",
    "\n",
    "    val_metrics[\"loss\"].append(np.mean(loss_value))\n",
    "    val_metrics[\"iou\"].append(iou_value)\n",
    "    val_metrics[\"f1\"].append(f1_score_value)\n",
    "    val_metrics[\"precision\"].append(presicion_value)\n",
    "    val_metrics[\"recall\"].append(recall_value)\n",
    "\n",
    "    # print(X[:, :, 0].shape, raw.shape, y.shape, pred.shape)\n",
    "    final_img = cv2.hconcat([\n",
    "        np.array(X[:, :, 0] * 255, dtype=np.uint8),\n",
    "        np.array(raw * 255, dtype=np.uint8),\n",
    "        np.array(y * 255, dtype=np.uint8),\n",
    "        np.array(pred * 255, dtype=np.uint8)\n",
    "        # np.array(thresh)\n",
    "    ])\n",
    "    cv2.imwrite(\"pred_samples/{:.4f}_{}_image.png\".format(iou_value, i), final_img)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a32f5061fcf236c4e6fcbf0f08e30b66d2a94d65fcc5ab372fe6f428f3c84fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
