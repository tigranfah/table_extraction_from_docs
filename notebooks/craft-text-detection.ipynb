{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../scripts/\")\n",
    "\n",
    "import utils\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_PATH = \"../datasets/all_ds/SciTSR/\"\n",
    "train_names, test_names = os.listdir(DS_PATH + \"train/img\"), os.listdir(DS_PATH + \"test/img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "Copyright (c) 2019-present NAVER Corp.\n",
    "MIT License\n",
    "\"\"\"\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "\"\"\" auxilary functions \"\"\"\n",
    "# unwarp corodinates\n",
    "def warpCoord(Minv, pt):\n",
    "    out = np.matmul(Minv, (pt[0], pt[1], 1))\n",
    "    return np.array([out[0]/out[2], out[1]/out[2]])\n",
    "\"\"\" end of auxilary functions \"\"\"\n",
    "\n",
    "\n",
    "def getDetBoxes_core(textmap, linkmap, text_threshold, link_threshold, low_text):\n",
    "    # prepare data\n",
    "    linkmap = linkmap.copy()\n",
    "    textmap = textmap.copy()\n",
    "    img_h, img_w = textmap.shape\n",
    "\n",
    "    \"\"\" labeling method \"\"\"\n",
    "    ret, text_score = cv2.threshold(textmap, low_text, 1, 0)\n",
    "    ret, link_score = cv2.threshold(linkmap, link_threshold, 1, 0)\n",
    "\n",
    "    text_score_comb = np.clip(text_score + link_score, 0, 1)\n",
    "    nLabels, labels, stats, centroids = cv2.connectedComponentsWithStats(text_score_comb.astype(np.uint8), connectivity=4)\n",
    "\n",
    "    det = []\n",
    "    mapper = []\n",
    "    for k in range(1,nLabels):\n",
    "        # size filtering\n",
    "        size = stats[k, cv2.CC_STAT_AREA]\n",
    "        if size < 10: continue\n",
    "\n",
    "        # thresholding\n",
    "        if np.max(textmap[labels==k]) < text_threshold: continue\n",
    "\n",
    "        # make segmentation map\n",
    "        segmap = np.zeros(textmap.shape, dtype=np.uint8)\n",
    "        segmap[labels==k] = 255\n",
    "        segmap[np.logical_and(link_score==1, text_score==0)] = 0   # remove link area\n",
    "        x, y = stats[k, cv2.CC_STAT_LEFT], stats[k, cv2.CC_STAT_TOP]\n",
    "        w, h = stats[k, cv2.CC_STAT_WIDTH], stats[k, cv2.CC_STAT_HEIGHT]\n",
    "        niter = int(math.sqrt(size * min(w, h) / (w * h)) * 2)\n",
    "        sx, ex, sy, ey = x - niter, x + w + niter + 1, y - niter, y + h + niter + 1\n",
    "        # boundary check\n",
    "        if sx < 0 : sx = 0\n",
    "        if sy < 0 : sy = 0\n",
    "        if ex >= img_w: ex = img_w\n",
    "        if ey >= img_h: ey = img_h\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(1 + niter, 1 + niter))\n",
    "        segmap[sy:ey, sx:ex] = cv2.dilate(segmap[sy:ey, sx:ex], kernel)\n",
    "\n",
    "        # make box\n",
    "        np_contours = np.roll(np.array(np.where(segmap!=0)),1,axis=0).transpose().reshape(-1,2)\n",
    "        rectangle = cv2.minAreaRect(np_contours)\n",
    "        box = cv2.boxPoints(rectangle)\n",
    "\n",
    "        # align diamond-shape\n",
    "        w, h = np.linalg.norm(box[0] - box[1]), np.linalg.norm(box[1] - box[2])\n",
    "        box_ratio = max(w, h) / (min(w, h) + 1e-5)\n",
    "        if abs(1 - box_ratio) <= 0.1:\n",
    "            l, r = min(np_contours[:,0]), max(np_contours[:,0])\n",
    "            t, b = min(np_contours[:,1]), max(np_contours[:,1])\n",
    "            box = np.array([[l, t], [r, t], [r, b], [l, b]], dtype=np.float32)\n",
    "\n",
    "        # make clock-wise order\n",
    "        startidx = box.sum(axis=1).argmin()\n",
    "        box = np.roll(box, 4-startidx, 0)\n",
    "        box = np.array(box)\n",
    "\n",
    "        det.append(box)\n",
    "        mapper.append(k)\n",
    "\n",
    "    return det, labels, mapper\n",
    "\n",
    "def getPoly_core(boxes, labels, mapper, linkmap):\n",
    "    # configs\n",
    "    num_cp = 5\n",
    "    max_len_ratio = 0.7\n",
    "    expand_ratio = 1.45\n",
    "    max_r = 2.0\n",
    "    step_r = 0.2\n",
    "\n",
    "    polys = []  \n",
    "    for k, box in enumerate(boxes):\n",
    "        # size filter for small instance\n",
    "        w, h = int(np.linalg.norm(box[0] - box[1]) + 1), int(np.linalg.norm(box[1] - box[2]) + 1)\n",
    "        if w < 10 or h < 10:\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # warp image\n",
    "        tar = np.float32([[0,0],[w,0],[w,h],[0,h]])\n",
    "        M = cv2.getPerspectiveTransform(box, tar)\n",
    "        word_label = cv2.warpPerspective(labels, M, (w, h), flags=cv2.INTER_NEAREST)\n",
    "        try:\n",
    "            Minv = np.linalg.inv(M)\n",
    "        except:\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # binarization for selected label\n",
    "        cur_label = mapper[k]\n",
    "        word_label[word_label != cur_label] = 0\n",
    "        word_label[word_label > 0] = 1\n",
    "\n",
    "        \"\"\" Polygon generation \"\"\"\n",
    "        # find top/bottom contours\n",
    "        cp = []\n",
    "        max_len = -1\n",
    "        for i in range(w):\n",
    "            region = np.where(word_label[:,i] != 0)[0]\n",
    "            if len(region) < 2 : continue\n",
    "            cp.append((i, region[0], region[-1]))\n",
    "            length = region[-1] - region[0] + 1\n",
    "            if length > max_len: max_len = length\n",
    "\n",
    "        # pass if max_len is similar to h\n",
    "        if h * max_len_ratio < max_len:\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # get pivot points with fixed length\n",
    "        tot_seg = num_cp * 2 + 1\n",
    "        seg_w = w / tot_seg     # segment width\n",
    "        pp = [None] * num_cp    # init pivot points\n",
    "        cp_section = [[0, 0]] * tot_seg\n",
    "        seg_height = [0] * num_cp\n",
    "        seg_num = 0\n",
    "        num_sec = 0\n",
    "        prev_h = -1\n",
    "        for i in range(0,len(cp)):\n",
    "            (x, sy, ey) = cp[i]\n",
    "            if (seg_num + 1) * seg_w <= x and seg_num <= tot_seg:\n",
    "                # average previous segment\n",
    "                if num_sec == 0: break\n",
    "                cp_section[seg_num] = [cp_section[seg_num][0] / num_sec, cp_section[seg_num][1] / num_sec]\n",
    "                num_sec = 0\n",
    "\n",
    "                # reset variables\n",
    "                seg_num += 1\n",
    "                prev_h = -1\n",
    "\n",
    "            # accumulate center points\n",
    "            cy = (sy + ey) * 0.5\n",
    "            cur_h = ey - sy + 1\n",
    "            cp_section[seg_num] = [cp_section[seg_num][0] + x, cp_section[seg_num][1] + cy]\n",
    "            num_sec += 1\n",
    "\n",
    "            if seg_num % 2 == 0: continue # No polygon area\n",
    "\n",
    "            if prev_h < cur_h:\n",
    "                pp[int((seg_num - 1)/2)] = (x, cy)\n",
    "                seg_height[int((seg_num - 1)/2)] = cur_h\n",
    "                prev_h = cur_h\n",
    "\n",
    "        # processing last segment\n",
    "        if num_sec != 0:\n",
    "            cp_section[-1] = [cp_section[-1][0] / num_sec, cp_section[-1][1] / num_sec]\n",
    "\n",
    "        # pass if num of pivots is not sufficient or segment widh is smaller than character height \n",
    "        if None in pp or seg_w < np.max(seg_height) * 0.25:\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # calc median maximum of pivot points\n",
    "        half_char_h = np.median(seg_height) * expand_ratio / 2\n",
    "\n",
    "        # calc gradiant and apply to make horizontal pivots\n",
    "        new_pp = []\n",
    "        for i, (x, cy) in enumerate(pp):\n",
    "            dx = cp_section[i * 2 + 2][0] - cp_section[i * 2][0]\n",
    "            dy = cp_section[i * 2 + 2][1] - cp_section[i * 2][1]\n",
    "            if dx == 0:     # gradient if zero\n",
    "                new_pp.append([x, cy - half_char_h, x, cy + half_char_h])\n",
    "                continue\n",
    "            rad = - math.atan2(dy, dx)\n",
    "            c, s = half_char_h * math.cos(rad), half_char_h * math.sin(rad)\n",
    "            new_pp.append([x - s, cy - c, x + s, cy + c])\n",
    "\n",
    "        # get edge points to cover character heatmaps\n",
    "        isSppFound, isEppFound = False, False\n",
    "        grad_s = (pp[1][1] - pp[0][1]) / (pp[1][0] - pp[0][0]) + (pp[2][1] - pp[1][1]) / (pp[2][0] - pp[1][0])\n",
    "        grad_e = (pp[-2][1] - pp[-1][1]) / (pp[-2][0] - pp[-1][0]) + (pp[-3][1] - pp[-2][1]) / (pp[-3][0] - pp[-2][0])\n",
    "        for r in np.arange(0.5, max_r, step_r):\n",
    "            dx = 2 * half_char_h * r\n",
    "            if not isSppFound:\n",
    "                line_img = np.zeros(word_label.shape, dtype=np.uint8)\n",
    "                dy = grad_s * dx\n",
    "                p = np.array(new_pp[0]) - np.array([dx, dy, dx, dy])\n",
    "                cv2.line(line_img, (int(p[0]), int(p[1])), (int(p[2]), int(p[3])), 1, thickness=1)\n",
    "                if np.sum(np.logical_and(word_label, line_img)) == 0 or r + 2 * step_r >= max_r:\n",
    "                    spp = p\n",
    "                    isSppFound = True\n",
    "            if not isEppFound:\n",
    "                line_img = np.zeros(word_label.shape, dtype=np.uint8)\n",
    "                dy = grad_e * dx\n",
    "                p = np.array(new_pp[-1]) + np.array([dx, dy, dx, dy])\n",
    "                cv2.line(line_img, (int(p[0]), int(p[1])), (int(p[2]), int(p[3])), 1, thickness=1)\n",
    "                if np.sum(np.logical_and(word_label, line_img)) == 0 or r + 2 * step_r >= max_r:\n",
    "                    epp = p\n",
    "                    isEppFound = True\n",
    "            if isSppFound and isEppFound:\n",
    "                break\n",
    "\n",
    "        # pass if boundary of polygon is not found\n",
    "        if not (isSppFound and isEppFound):\n",
    "            polys.append(None); continue\n",
    "\n",
    "        # make final polygon\n",
    "        poly = []\n",
    "        poly.append(warpCoord(Minv, (spp[0], spp[1])))\n",
    "        for p in new_pp:\n",
    "            poly.append(warpCoord(Minv, (p[0], p[1])))\n",
    "        poly.append(warpCoord(Minv, (epp[0], epp[1])))\n",
    "        poly.append(warpCoord(Minv, (epp[2], epp[3])))\n",
    "        for p in reversed(new_pp):\n",
    "            poly.append(warpCoord(Minv, (p[2], p[3])))\n",
    "        poly.append(warpCoord(Minv, (spp[2], spp[3])))\n",
    "\n",
    "        # add to final result\n",
    "        polys.append(np.array(poly))\n",
    "\n",
    "    return polys\n",
    "\n",
    "def getDetBoxes(textmap, linkmap, text_threshold, link_threshold, low_text, poly=False):\n",
    "    boxes, labels, mapper = getDetBoxes_core(textmap, linkmap, text_threshold, link_threshold, low_text)\n",
    "\n",
    "    if poly:\n",
    "        polys = getPoly_core(boxes, labels, mapper, linkmap)\n",
    "    else:\n",
    "        polys = [None] * len(boxes)\n",
    "\n",
    "    return boxes, polys\n",
    "\n",
    "def adjustResultCoordinates(polys, ratio_w, ratio_h, ratio_net = 2):\n",
    "    if len(polys) > 0:\n",
    "        polys = np.array(polys)\n",
    "        for k in range(len(polys)):\n",
    "            if polys[k] is not None:\n",
    "                polys[k] *= (ratio_w * ratio_net, ratio_h * ratio_net)\n",
    "    return polys\n",
    "\n",
    "def cvt2HeatmapImg(img):\n",
    "    img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
    "    img = cv2.applyColorMap(img, cv2.COLORMAP_JET)\n",
    "    return img\n",
    "\n",
    "def saveResult(img_file, img, boxes, dirname='./result/', verticals=None, texts=None):\n",
    "    \"\"\" save text detection result one by one\n",
    "    Args:\n",
    "        img_file (str): image file name\n",
    "        img (array): raw image context\n",
    "        boxes (array): array of result file\n",
    "            Shape: [num_detections, 4] for BB output / [num_detections, 4] for QUAD output\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    img = np.array(img)\n",
    "\n",
    "    # make result file list\n",
    "    filename, file_ext = os.path.splitext(os.path.basename(img_file))\n",
    "\n",
    "    # result directory\n",
    "    res_file = dirname + \"res_\" + filename + '.txt'\n",
    "    res_img_file = dirname + \"res_\" + filename + '.jpg'\n",
    "\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.mkdir(dirname)\n",
    "\n",
    "    with open(res_file, 'w') as f:\n",
    "        for i, box in enumerate(boxes):\n",
    "            poly = np.array(box).astype(np.int32).reshape((-1))\n",
    "            strResult = ','.join([str(p) for p in poly]) + '\\r\\n'\n",
    "            f.write(strResult)\n",
    "\n",
    "            poly = poly.reshape(-1, 2)\n",
    "            cv2.polylines(img, [poly.reshape((-1, 1, 2))], True, color=(0, 0, 255), thickness=2)\n",
    "            ptColor = (0, 255, 255)\n",
    "            if verticals is not None:\n",
    "                if verticals[i]:\n",
    "                    ptColor = (255, 0, 0)\n",
    "\n",
    "            if texts is not None:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                font_scale = 0.5\n",
    "                cv2.putText(img, \"{}\".format(texts[i]), (poly[0][0]+1, poly[0][1]+1), font, font_scale, (0, 0, 0), thickness=1)\n",
    "                cv2.putText(img, \"{}\".format(texts[i]), tuple(poly[0]), font, font_scale, (0, 255, 255), thickness=1)\n",
    "\n",
    "    # Save result image\n",
    "    cv2.imwrite(res_img_file, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "variance = (0.229, 0.224, 0.225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_inp(name, devide=True):\n",
    "    orig_img = cv2.imread(DS_PATH + \"train/img/\" + name)\n",
    "    # print(orig_img)\n",
    "    resized_image = cv2.resize(orig_img, (600*2, 800))\n",
    "    # print(resized_image.shape)\n",
    "    fill_img = np.moveaxis(resized_image, -1, 0)\n",
    "    # print(fill_img.shape)\n",
    "    fill_img = np.array([\n",
    "                (fill_img[0] - mean[0]*255) / (variance[0]*255),\n",
    "                (fill_img[1] - mean[1]*255) / (variance[1]*255),\n",
    "                (fill_img[2] - mean[2]*255) / (variance[2]*255)\n",
    "            ])\n",
    "\n",
    "    if devide:\n",
    "        img_left, img_right = fill_img[:, :, :600], fill_img[:, :, 600:]\n",
    "        orig_img_left, orig_img_right = resized_image[:, :600, :], resized_image[:, 600:, :]\n",
    "        return tf.convert_to_tensor(img_left, dtype=tf.float32), orig_img_left, tf.convert_to_tensor(img_right, dtype=tf.float32), orig_img_right\n",
    "        # print(img_left.shape, img_right.shape)\n",
    "        # images = []\n",
    "        # for d in range(devide):\n",
    "        #     scaled_img = \n",
    "        #     images\n",
    "\n",
    "    return tf.convert_to_tensor(fill_img, dtype=tf.float32), orig_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/cseadmin/Tigran/table_extractor/notebooks/craft-text-detection.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cseadmin/Tigran/table_extractor/notebooks/craft-text-detection.ipynb#ch0000005?line=0'>1</a>\u001b[0m img1, im1, img2, im2 \u001b[39m=\u001b[39m read_inp(train_names[\u001b[39m2\u001b[39m], \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_names' is not defined"
     ]
    }
   ],
   "source": [
    "img1, im1, img2, im2 = read_inp(train_names[2], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.shape, im1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(im1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(\"../models/lite-model_craft-text-detector_float16_1.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_name):\n",
    "    imgl, orl, imgr, orr = read_inp(image_name, devide=True)\n",
    "    # print(imgl.shape, imgr.shape)\n",
    "    \n",
    "    res = []\n",
    "\n",
    "    for im_inp, im_orig in zip([imgl, imgr], [orl, orr]):\n",
    "        # print(np.all(im_inp == imgr))\n",
    "        interpreter.set_tensor(input_details[0]['index'], tf.expand_dims(im_inp, 0))\n",
    "        interpreter.invoke()\n",
    "\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        \n",
    "        score_text = np.array(output_data[0,:,:,0])\n",
    "        score_link = np.array(output_data[0,:,:,1])\n",
    "\n",
    "        # Post-processing\n",
    "        boxes, polys = getDetBoxes(score_text, score_link, 0.7, 0.4, 0.4, False)\n",
    "        # print(len(boxes))\n",
    "        # print(boxes)\n",
    "        # coordinate adjustments\n",
    "        boxes = adjustResultCoordinates(boxes, 1, 1)\n",
    "        polys = adjustResultCoordinates(polys, 1, 1)\n",
    "        for k in range(len(polys)):\n",
    "            if polys[k] is None: polys[k] = boxes[k]\n",
    "\n",
    "        img_out = im_orig.copy()\n",
    "        for i, box in enumerate(polys):\n",
    "            poly = np.array(box).astype(np.int32).reshape((-1))\n",
    "            strResult = ', '.join([str(p) for p in poly]) + '\\r\\n'\n",
    "\n",
    "            poly = poly.reshape(-1, 2)\n",
    "            cv2.polylines(img_out, [poly.reshape((-1, 1, 2))], True, color=(0, 0, 255), thickness=1)\n",
    "            ptColor = (0, 255, 255)\n",
    "\n",
    "        res.append(img_out)\n",
    "    \n",
    "    return cv2.hconcat([\n",
    "        res[0], res[1]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(train_names[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a32f5061fcf236c4e6fcbf0f08e30b66d2a94d65fcc5ab372fe6f428f3c84fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
