{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/cseadmin/Tigran/table_extractor/notebooks/../scripts/utils.py'>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, \"../scripts/\")\n",
    "\n",
    "from utils import train_test_split, image_batch_generator, get_train_augmentation, random_batch_generator, get_table_augmentation\n",
    "from utils import DATASET_PATH, DS_IMAGES, DS_MASKS, SaveValidSamplesCallback\n",
    "import utils\n",
    "from metrics import iou, f1_score, jaccard_distance\n",
    "import metrics\n",
    "from vis import anshow, imshow\n",
    "import vis\n",
    "from models import TableNet, load_unet_model\n",
    "\n",
    "IMAGE_NAMES = os.listdir(DS_IMAGES)\n",
    "\n",
    "import importlib\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(vis)\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    model = load_unet_model((512, 512), 2, weight_decay=0.1)\n",
    "    optim = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint training_checkpoints/2022.08.03-13/ckpt-347\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    checkpoint = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optim, net=model)\n",
    "    print(f\"loading checkpoint {'training_checkpoints/' + '2022.08.03-13/ckpt-347'}\")\n",
    "    status = checkpoint.restore(\"../scripts/training_checkpoints/\" + '2022.08.03-13/ckpt-347')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = jaccard_distance\n",
    "\n",
    "train_names, valid_names = train_test_split(IMAGE_NAMES, shuffle=True, random_state=2022, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batch_generator = image_batch_generator(\n",
    "                            valid_names, \n",
    "                            batch_size=1, \n",
    "                            resize_shape=(512, 512),\n",
    "                            aug_transform=None,\n",
    "                            normalize=True, include_edges_as_band=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(name, metrics, step, all_steps):\n",
    "    str_prog = f\"{all_steps}/{step}: \"\n",
    "    str_prog += \"{} loss {:.4f}, tf_iou {:.4f}, iou {:.4f}, f1 {:.4f}, prec {:.4f}, rec {:.4f}\".format(\n",
    "        name,\n",
    "        np.mean(metrics[\"loss\"]),\n",
    "        np.mean(metrics[\"tf_iou\"]),  \n",
    "        np.mean(metrics[\"iou\"]), \n",
    "        np.mean(metrics[\"f1\"]),\n",
    "        np.mean(metrics[\"precision\"]),\n",
    "        np.mean(metrics[\"recall\"])\n",
    "    )\n",
    "\n",
    "    print(str_prog, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device(\"CPU:0\"):\n",
    "#     val_metrics = {n:[] for n in (\"loss\", \"tf_iou\", \"iou\", \"f1\", \"precision\", \"recall\")}\n",
    "\n",
    "#     mean_time = []\n",
    "\n",
    "#     # valid loop\n",
    "#     # with tf.device(\"GPU:0\"):\n",
    "\n",
    "#     for i, (batch_X, batch_y) in enumerate(valid_batch_generator):\n",
    "\n",
    "#         start = time.time()\n",
    "\n",
    "#         # print(batch_X.dtype, batch_y.dtype)\n",
    "#         # print(batch_y.min(), batch_y.max())\n",
    "#         batch_X = tf.convert_to_tensor(batch_X, dtype=tf.float32)\n",
    "#         batch_y = tf.convert_to_tensor(batch_y, dtype=tf.float32)\n",
    "\n",
    "#         logits = model(batch_X, training=False)\n",
    "#         logits = tf.squeeze(logits)\n",
    "\n",
    "#         # rgb_masks = np.array(logits * 255, dtype=np.uint8)\n",
    "#         # final_masks = []\n",
    "\n",
    "#         # for mask in rgb_masks:\n",
    "\n",
    "#         #     thresh = thresh = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "#         #     contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#         #     final_mask = np.zeros_like(mask)\n",
    "\n",
    "#         #     for ind, c in enumerate(contours):\n",
    "#         #         if len(c) > 100:\n",
    "#         #             min_x, max_x = np.squeeze(c)[:, 0].min(), np.squeeze(c)[:, 0].max()\n",
    "#         #             min_y, max_y = np.squeeze(c)[:, 1].min(), np.squeeze(c)[:, 1].max()\n",
    "#         #             final_mask[min_y:max_y, min_x:max_x] = 1\n",
    "\n",
    "#         #     final_masks.append(final_mask)\n",
    "\n",
    "#         # final_masks = tf.convert_to_tensor(final_masks, np.float32)\n",
    "\n",
    "#         # print(np.unique(final_masks))\n",
    "\n",
    "#         # print([metrics.iou(gt, pr) for gt, pr in zip(batch_y, final_masks)])\n",
    "#         # break\n",
    "\n",
    "#         loss_value = loss_fn(batch_y, logits)\n",
    "#         # print(loss_value)\n",
    "\n",
    "#         (\n",
    "#             iou_value, tf_iou_value,\n",
    "#             f1_score_value, \n",
    "#             presicion_value, \n",
    "#             recall_value\n",
    "#         ) = metrics.calculate_metrics(batch_y, logits)\n",
    "#         val_metrics[\"loss\"].append(np.mean(loss_value))\n",
    "#         val_metrics[\"tf_iou\"].append(tf_iou_value)\n",
    "#         val_metrics[\"iou\"].append(iou_value)\n",
    "#         val_metrics[\"f1\"].append(f1_score_value)\n",
    "#         val_metrics[\"precision\"].append(presicion_value)\n",
    "#         val_metrics[\"recall\"].append(recall_value)\n",
    "\n",
    "#         # break\n",
    "\n",
    "#         mean_time.append(time.time() - start)\n",
    "#         # print(f\"{len(valid_names)//8}/{i+1}\", end='\\r')\n",
    "#         print_progress(\"valid\", val_metrics, i+1, len(valid_names)//8)\n",
    "#         # break\n",
    "#         if (i + 1) >= len(valid_names)//8:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    batch_X, batch_y = utils.read_inf_sample(valid_names[:50], (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = {n:[] for n in (\"loss\", \"iou\", \"tf_iou\", \"f1\", \"precision\", \"recall\")}\n",
    "mean_time = []\n",
    "\n",
    "with tf.device(\"/CPU:0\"):\n",
    "\n",
    "    for i, (X, y) in enumerate(zip(batch_X, batch_y)):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        raw = model(tf.expand_dims(X, 0), training=False)\n",
    "        raw = tf.squeeze(raw)\n",
    "\n",
    "        pred1 = utils.preprocess_raw_output(raw, 2, 100)\n",
    "        pred2 = utils.preprocess_raw_output(pred1, 2, 2000, max_seg_dist=40)\n",
    "        # pred2 = utils.preprocess_raw_output(pred2, 2, 0, max_seg_dist=20)\n",
    "        # pred2 = utils.preprocess_raw_output(pred2, 2, 0)\n",
    "\n",
    "        mean_time.append(time.time() - start)\n",
    "        # print(y.shape, pred.shape)\n",
    "\n",
    "        loss_value = loss_fn(tf.expand_dims(y, 0), tf.expand_dims(pred2, 0))\n",
    "        (\n",
    "            iou_value, tf_iou_value,\n",
    "            f1_score_value,\n",
    "            presicion_value, \n",
    "            recall_value\n",
    "        ) = metrics.calculate_metrics([y], [pred2])\n",
    "\n",
    "        val_metrics[\"loss\"].append(np.mean(loss_value))\n",
    "        val_metrics[\"iou\"].append(iou_value)\n",
    "        val_metrics[\"tf_iou\"].append(tf_iou_value)\n",
    "        val_metrics[\"f1\"].append(f1_score_value)\n",
    "        val_metrics[\"precision\"].append(presicion_value)\n",
    "        val_metrics[\"recall\"].append(recall_value)\n",
    "\n",
    "        # print(X[:, :, 0].shape, raw.shape, y.shape, pred.shape)\n",
    "        final_img = cv2.hconcat([\n",
    "            np.array(X[:, :, 0] * 255, dtype=np.uint8),\n",
    "            np.array(raw * 255, dtype=np.uint8),\n",
    "            np.array(y * 255, dtype=np.uint8),\n",
    "            np.array(pred1 * 255, dtype=np.uint8),\n",
    "            np.array(pred2 * 255, dtype=np.uint8)\n",
    "            # np.array(thresh)\n",
    "        ])\n",
    "        cv2.imwrite(\"pred_samples/{:.4f}_{}_image.png\".format(iou_value, i), final_img)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7750808954238891"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1: valid loss 22.9774, tf_iou 0.8437, iou 0.6292, f1 0.8094, prec 0.6996, rec 0.6683\r"
     ]
    }
   ],
   "source": [
    "print_progress(\"valid\", val_metrics, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a32f5061fcf236c4e6fcbf0f08e30b66d2a94d65fcc5ab372fe6f428f3c84fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
