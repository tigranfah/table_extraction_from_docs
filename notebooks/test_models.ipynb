{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/tigran-analysed/Desktop/analysed.ai/table_extractor/notebooks/../scripts/utils.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, \"../scripts/\")\n",
    "\n",
    "from utils import train_test_split, image_batch_generator, get_train_augmentation, random_batch_generator, get_table_augmentation\n",
    "from utils import DATASET_PATH, DS_IMAGES, DS_MASKS, SaveValidSamplesCallback\n",
    "import utils\n",
    "from metrics import iou, f1_score, jaccard_distance\n",
    "import metrics\n",
    "from vis import anshow, imshow\n",
    "import vis\n",
    "from models import TableNet, load_unet_model\n",
    "\n",
    "IMAGE_NAMES = os.listdir(DS_IMAGES)\n",
    "\n",
    "import importlib\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(vis)\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 15:07:19.522588: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/tigran-analysed/Desktop/analysed.ai/table_extractor/venv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-08-15 15:07:19.522664: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-15 15:07:19.522715: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tigrananalysed-System-Product-Name): /proc/driver/nvidia/version does not exist\n",
      "2022-08-15 15:07:19.523228: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = load_unet_model((512, 512), 2, weight_decay=0.1)\n",
    "optim = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f7387e5af80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1), optimizer=tf.keras.optimizers.Adam(), net=model)\n",
    "# print(f\"loading checkpoint {'training_checkpoints/' + '2022.07.30-22/' + 'ckpt-238'}\")\n",
    "status = checkpoint.restore(\"../checkpoints/ckpt-624\")\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = jaccard_distance\n",
    "\n",
    "train_names, valid_names = train_test_split(IMAGE_NAMES, shuffle=True, random_state=2022, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "805"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batch_generator = image_batch_generator(\n",
    "                            valid_names, \n",
    "                            batch_size=1, \n",
    "                            resize_shape=(512, 512),\n",
    "                            aug_transform=None,\n",
    "                            normalize=True, include_edges_as_band=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(name, metrics, step, all_steps):\n",
    "    str_prog = f\"{all_steps}/{step}: \"\n",
    "    str_prog += \"{} loss {:.4f}, tf_iou {:.4f}, iou {:.4f}, f1 {:.4f}, prec {:.4f}, rec {:.4f}\".format(\n",
    "        name,\n",
    "        np.mean(metrics[\"loss\"]),\n",
    "        np.mean(metrics[\"tf_iou\"]),\n",
    "        np.mean(metrics[\"iou\"]), \n",
    "        np.mean(metrics[\"f1\"]),\n",
    "        np.mean(metrics[\"precision\"]),\n",
    "        np.mean(metrics[\"recall\"])\n",
    "    )\n",
    "\n",
    "    print(str_prog, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X, batch_y = utils.read_inf_sample(valid_names[:50], (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = {n:[] for n in (\"loss\", \"iou\", \"tf_iou\", \"f1\", \"precision\", \"recall\")}\n",
    "mean_time = []\n",
    "\n",
    "for i, (X, y, name) in enumerate(zip(batch_X, batch_y, valid_names)):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    raw = model(tf.expand_dims(X, 0), training=False)\n",
    "    raw = tf.squeeze(raw)\n",
    "\n",
    "    pred1 = utils.preprocess_raw_output(raw, 2, 1000)\n",
    "    pred2 = utils.preprocess_raw_output(pred1, 2, 0, max_seg_dist=50)\n",
    "    # pred2 = utils.preprocess_raw_output(pred2, 2, 0, max_seg_dist=20)\n",
    "    # pred2 = utils.preprocess_raw_output(pred2, 2, 0)\n",
    "\n",
    "    mean_time.append(time.time() - start)\n",
    "    # print(y.shape, pred.shape)\n",
    "\n",
    "    loss_value = loss_fn(tf.expand_dims(y, 0), tf.expand_dims(pred2, 0))\n",
    "    (\n",
    "        iou_value, tf_iou_value,\n",
    "        f1_score_value,\n",
    "        presicion_value, \n",
    "        recall_value\n",
    "    ) = metrics.calculate_metrics([y], [pred2])\n",
    "\n",
    "    val_metrics[\"loss\"].append(np.mean(loss_value))\n",
    "    val_metrics[\"iou\"].append(iou_value)\n",
    "    val_metrics[\"tf_iou\"].append(tf_iou_value)\n",
    "    val_metrics[\"f1\"].append(f1_score_value)\n",
    "    val_metrics[\"precision\"].append(presicion_value)\n",
    "    val_metrics[\"recall\"].append(recall_value)\n",
    "\n",
    "    # print(X[:, :, 0].shape, raw.shape, y.shape, pred.shape)\n",
    "    final_img = cv2.hconcat([\n",
    "        np.array(X[:, :, 0] * 255, dtype=np.uint8),\n",
    "        np.array(raw * 255, dtype=np.uint8),\n",
    "        np.array(y * 255, dtype=np.uint8),\n",
    "        np.array(pred1 * 255, dtype=np.uint8),\n",
    "        np.array(pred2 * 255, dtype=np.uint8)\n",
    "        # np.array(thresh)\n",
    "    ])\n",
    "\n",
    "    b_n, ext = os.path.splitext(name)\n",
    "    cv2.imwrite(\"pred_samples/{:.4f}_{}.png\".format(iou_value, name), final_img)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "892f614baa9d04519f1f731f14ca3156f1c72908f1be1277dcf0c7c8a00f770c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
