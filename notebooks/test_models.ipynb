{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'c:\\\\Users\\\\user\\\\Desktop\\\\analysed.ai\\\\table_extraction_from_docs\\\\notebooks\\\\../scripts\\\\utils.py'>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, \"../scripts/\")\n",
    "sys.path.insert(0, os.path.join(\"..\", \"keras_unets\"))\n",
    "\n",
    "from utils import train_test_split, image_batch_generator, get_train_augmentation, random_batch_generator, get_table_augmentation\n",
    "from utils import DATASET_PATH, DS_IMAGES, DS_MASKS, PAGE_IMAGES, SaveValidSamplesCallback\n",
    "import utils\n",
    "from metrics import iou, f1_score, jaccard_distance\n",
    "import metrics\n",
    "from vis import anshow, imshow\n",
    "import vis\n",
    "from models import TableNet, load_unet_model\n",
    "\n",
    "from keras_unet_collection.models import att_unet_2d\n",
    "\n",
    "IMAGE_NAMES = os.listdir(DS_IMAGES) + os.listdir(PAGE_IMAGES)\n",
    "\n",
    "import importlib\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(vis)\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR_CONFIG = {\n",
    "    \"epochs\" : 100,\n",
    "    \"batch_size\" : 7,\n",
    "    # \"val_batch_size\" : 32,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"input_shape\" : (512, 512),\n",
    "    \"band_size\" : 2,\n",
    "    \"three_channel\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint training_checkpoints/2022.08.28-14/ckpt-114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2be6a592fb0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_scales = [32, 64, 128, 256]\n",
    "# down_scales = [16, 32, 64, 128]\n",
    "model = att_unet_2d((TR_CONFIG[\"input_shape\"][0], TR_CONFIG[\"input_shape\"][1], 2), down_scales, n_labels=1,\n",
    "            stack_num_down=2, stack_num_up=2,\n",
    "            activation='ReLU', atten_activation='ReLU', attention='add', output_activation=\"Sigmoid\", \n",
    "            batch_norm=True, pool=False, unpool='bilinear', name='attunet'\n",
    "        )\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1), optimizer=tf.keras.optimizers.Adam(), net=model)\n",
    "print(f\"loading checkpoint {'training_checkpoints/' + '2022.08.28-14/ckpt-114'}\")\n",
    "status = checkpoint.restore(\"../scripts/training_checkpoints/\" + '2022.08.28-14/ckpt-114')\n",
    "status.expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_generator = image_batch_generator(\n",
    "                            IMAGE_NAMES, \n",
    "                            batch_size=TR_CONFIG[\"batch_size\"], \n",
    "                            resize_shape=TR_CONFIG[\"input_shape\"],\n",
    "                            aug_transform=None,\n",
    "                            normalize=True, three_channel=TR_CONFIG[\"three_channel\"],\n",
    "                            return_names=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(name, metrics, step, all_steps):\n",
    "    str_prog = f\"{all_steps}/{step}: \"\n",
    "    str_prog += \"{} loss {:.4f}, tf_iou {:.4f}, iou {:.4f}, f1 {:.4f}, prec {:.4f}, rec {:.4f}\".format(\n",
    "        name,\n",
    "        np.mean(metrics[\"loss\"]),\n",
    "        np.mean(metrics[\"tf_iou\"]),\n",
    "        np.mean(metrics[\"iou\"]),\n",
    "        np.mean(metrics[\"f1\"]),\n",
    "        np.mean(metrics[\"precision\"]),\n",
    "        np.mean(metrics[\"recall\"])\n",
    "    )\n",
    "\n",
    "    print(str_prog, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "884/884: valid loss 0.1263, tf_iou 0.8922, iou 0.8737, f1 0.9066, prec 0.9484, rec 0.9238\r"
     ]
    }
   ],
   "source": [
    "tr_metrics = {n:[] for n in (\"loss\", \"iou\", \"tf_iou\", \"f1\", \"precision\", \"recall\")}\n",
    "\n",
    "for i, (batch_X, batch_y, image_names) in enumerate(train_batch_generator):\n",
    "\n",
    "    # print(batch_X.dtype, batch_y.dtype)\n",
    "    # print(batch_y.min(), batch_y.max())\n",
    "    batch_X = tf.convert_to_tensor(batch_X, dtype=tf.float32)\n",
    "    batch_y = tf.convert_to_tensor(batch_y, dtype=tf.float32)\n",
    "    # print(type(data))\n",
    "\n",
    "    pred = model(batch_X, training=False)\n",
    "    pred = tf.squeeze(pred, -1)\n",
    "\n",
    "    loss_value = metrics.jaccard_distance(pred, batch_y)\n",
    "\n",
    "    for ind, (name, X, y, pred_y) in enumerate(zip(image_names, batch_X, batch_y, pred)):\n",
    "\n",
    "        mask = np.array(pred_y)\n",
    "        mask[mask < 0.9] = 0\n",
    "        pred_y = tf.convert_to_tensor(mask)\n",
    "        \n",
    "        iou_val = metrics.iou(y, pred_y) * 100\n",
    "\n",
    "        cv2.imwrite(\n",
    "            \"preds/{:.4f}_{}.png\".format(iou_val, name),\n",
    "            cv2.hconcat([\n",
    "                np.array(X[:, :, 0] * 255, dtype=np.uint8), \n",
    "                np.array(pred_y * 255, dtype=np.uint8), \n",
    "                np.array(y * 255, dtype=np.uint8)\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    (\n",
    "        iou_value, tf_iou_value,\n",
    "        f1_score_value, \n",
    "        presicion_value, \n",
    "        recall_value\n",
    "    ) = metrics.calculate_metrics(batch_y, pred)\n",
    "\n",
    "    tr_metrics[\"loss\"].append(loss_value)\n",
    "    tr_metrics[\"iou\"].append(iou_value)\n",
    "    tr_metrics[\"tf_iou\"].append(tf_iou_value)\n",
    "    tr_metrics[\"f1\"].append(f1_score_value)\n",
    "    tr_metrics[\"precision\"].append(presicion_value)\n",
    "    tr_metrics[\"recall\"].append(recall_value)\n",
    "\n",
    "    print_progress(\"valid\", tr_metrics, i+1, len(IMAGE_NAMES)//TR_CONFIG[\"batch_size\"])\n",
    "    # break\n",
    "    if (i + 1) >= len(IMAGE_NAMES)//TR_CONFIG[\"batch_size\"]:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = \"\"\"58_248\n",
    "85_250\n",
    "53_134\n",
    "85_231\n",
    "94_49\n",
    "6008_014\n",
    "90_111\n",
    "10.1.1.160.606_5\n",
    "21_72\n",
    "10.1.1.160.699_3\n",
    "77_126\n",
    "52_275\n",
    "10.1.1.160.659_3\n",
    "10.1.1.160.656_12\n",
    "10.1.1.160.652_9\n",
    "10.1.1.160.653_12\n",
    "41_50\n",
    "10.1.1.160.655_9\n",
    "21_133\n",
    "9_139\n",
    "2208-10297-pdf_page_10_jpg.rf.4266a173854f0a9cc83bd4910d994e29\n",
    "10.1.1.160.657_4\n",
    "74_29\n",
    "55_301\n",
    "10.1.1.1.2103_4\n",
    "30_4\n",
    "10.1.1.160.651_22\n",
    "44_92\n",
    "29_122\n",
    "29_15\n",
    "11_150\n",
    "33_252\n",
    "15_261\n",
    "81_90\n",
    "2208-10406-pdf_page_5_jpg.rf.b80a8a94650a8487b97770eb1ee5b977\n",
    "24_11\n",
    "15_111\n",
    "33_11\n",
    "4_16\n",
    "17_229\n",
    "1852_095\n",
    "63_59\n",
    "6286_013\n",
    "0651_008\n",
    "NFE_Roster_page_1_jpg.rf.310a7dec8cce7418a155705fd2651f2d\n",
    "NFE_Roster_page_0_jpg.rf.c30b226e49ac8dc4a9d6694059ab80a5\n",
    "10.1.1.38.2480_2\n",
    "5727_109\n",
    "5727_096\n",
    "5727_105\n",
    "2022_Freakout_JFDS-pdf_page_0_jpg.rf.0278be037a923592bce7969534d65532\"\"\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in names:\n",
    "    for ext in [\"jpg\", \"bmp\", \"png\", \"jpeg\"]:\n",
    "        if os.path.exists(f\"../datasets/all_images/{n}.{ext}\"):\n",
    "            removed += 1\n",
    "            os.remove(f\"../datasets/all_images/{n}.{ext}\")\n",
    "\n",
    "        if os.path.exists(f\"../datasets/all_masks/{n}_mask.{ext}\"):\n",
    "            # print(n, \"mask\")\n",
    "            os.remove(f\"../datasets/all_masks/{n}_mask.{ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "420bf6fecb2b2ef9bb99cd6d192db828789a38775f4d69e2e89a3f8de9ac3b4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
