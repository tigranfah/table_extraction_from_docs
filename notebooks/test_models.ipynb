{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/cseadmin/Tigran/table_extractor/notebooks/../scripts/utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, \"../scripts/\")\n",
    "\n",
    "from utils import train_test_split, image_batch_generator, get_train_augmentation, random_batch_generator, get_table_augmentation\n",
    "from utils import DATASET_PATH, DS_IMAGES, DS_MASKS, SaveValidSamplesCallback\n",
    "import utils\n",
    "from metrics import iou, f1_score, jaccard_distance\n",
    "import metrics\n",
    "from vis import anshow, imshow\n",
    "import vis\n",
    "from models import TableNet, load_unet_model\n",
    "\n",
    "IMAGE_NAMES = os.listdir(DS_IMAGES)\n",
    "\n",
    "import importlib\n",
    "importlib.reload(metrics)\n",
    "importlib.reload(vis)\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 14:35:46.119327: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-04 14:35:47.624432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 260 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    model = load_unet_model((512, 512), 2, weight_decay=0.1)\n",
    "    optim = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint training_checkpoints/2022.08.04-13/ckpt-468\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    checkpoint = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optim, net=model)\n",
    "    print(f\"loading checkpoint {'training_checkpoints/' + '2022.08.04-13/ckpt-468'}\")\n",
    "    status = checkpoint.restore(\"../scripts/training_checkpoints/\" + '2022.08.04-13/ckpt-468')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = jaccard_distance\n",
    "\n",
    "train_names, valid_names = train_test_split(IMAGE_NAMES, shuffle=True, random_state=2022, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_batch_generator = image_batch_generator(\n",
    "                            valid_names, \n",
    "                            batch_size=1, \n",
    "                            resize_shape=(512, 512),\n",
    "                            aug_transform=None,\n",
    "                            normalize=True, include_edges_as_band=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_progress(name, metrics, step, all_steps):\n",
    "    str_prog = f\"{all_steps}/{step}: \"\n",
    "    str_prog += \"{} loss {:.4f}, tf_iou {:.4f}, iou {:.4f}, f1 {:.4f}, prec {:.4f}, rec {:.4f}\".format(\n",
    "        name,\n",
    "        np.mean(metrics[\"loss\"]),\n",
    "        np.mean(metrics[\"tf_iou\"]),\n",
    "        np.mean(metrics[\"iou\"]), \n",
    "        np.mean(metrics[\"f1\"]),\n",
    "        np.mean(metrics[\"precision\"]),\n",
    "        np.mean(metrics[\"recall\"])\n",
    "    )\n",
    "\n",
    "    print(str_prog, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.device(\"CPU:0\"):\n",
    "#     val_metrics = {n:[] for n in (\"loss\", \"tf_iou\", \"iou\", \"f1\", \"precision\", \"recall\")}\n",
    "\n",
    "#     mean_time = []\n",
    "\n",
    "#     # valid loop\n",
    "#     # with tf.device(\"GPU:0\"):\n",
    "\n",
    "#     for i, (batch_X, batch_y) in enumerate(valid_batch_generator):\n",
    "\n",
    "#         start = time.time()\n",
    "\n",
    "#         # print(batch_X.dtype, batch_y.dtype)\n",
    "#         # print(batch_y.min(), batch_y.max())\n",
    "#         batch_X = tf.convert_to_tensor(batch_X, dtype=tf.float32)\n",
    "#         batch_y = tf.convert_to_tensor(batch_y, dtype=tf.float32)\n",
    "\n",
    "#         logits = model(batch_X, training=False)\n",
    "#         logits = tf.squeeze(logits)\n",
    "\n",
    "#         # rgb_masks = np.array(logits * 255, dtype=np.uint8)\n",
    "#         # final_masks = []\n",
    "\n",
    "#         # for mask in rgb_masks:\n",
    "\n",
    "#         #     thresh = thresh = cv2.threshold(mask, 200, 255, cv2.THRESH_BINARY)[1]\n",
    "#         #     contours, hierarchy = cv2.findContours(image=thresh, mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#         #     final_mask = np.zeros_like(mask)\n",
    "\n",
    "#         #     for ind, c in enumerate(contours):\n",
    "#         #         if len(c) > 100:\n",
    "#         #             min_x, max_x = np.squeeze(c)[:, 0].min(), np.squeeze(c)[:, 0].max()\n",
    "#         #             min_y, max_y = np.squeeze(c)[:, 1].min(), np.squeeze(c)[:, 1].max()\n",
    "#         #             final_mask[min_y:max_y, min_x:max_x] = 1\n",
    "\n",
    "#         #     final_masks.append(final_mask)\n",
    "\n",
    "#         # final_masks = tf.convert_to_tensor(final_masks, np.float32)\n",
    "\n",
    "#         # print(np.unique(final_masks))\n",
    "\n",
    "#         # print([metrics.iou(gt, pr) for gt, pr in zip(batch_y, final_masks)])\n",
    "#         # break\n",
    "\n",
    "#         loss_value = loss_fn(batch_y, logits)\n",
    "#         # print(loss_value)\n",
    "\n",
    "#         (\n",
    "#             iou_value, tf_iou_value,\n",
    "#             f1_score_value, \n",
    "#             presicion_value, \n",
    "#             recall_value\n",
    "#         ) = metrics.calculate_metrics(batch_y, logits)\n",
    "#         val_metrics[\"loss\"].append(np.mean(loss_value))\n",
    "#         val_metrics[\"tf_iou\"].append(tf_iou_value)\n",
    "#         val_metrics[\"iou\"].append(iou_value)\n",
    "#         val_metrics[\"f1\"].append(f1_score_value)\n",
    "#         val_metrics[\"precision\"].append(presicion_value)\n",
    "#         val_metrics[\"recall\"].append(recall_value)\n",
    "\n",
    "#         # break\n",
    "\n",
    "#         mean_time.append(time.time() - start)\n",
    "#         # print(f\"{len(valid_names)//8}/{i+1}\", end='\\r')\n",
    "#         print_progress(\"valid\", val_metrics, i+1, len(valid_names)//8)\n",
    "#         # break\n",
    "#         if (i + 1) >= len(valid_names)//8:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    batch_X, batch_y = utils.read_inf_sample(valid_names[:50], (512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metrics = {n:[] for n in (\"loss\", \"iou\", \"tf_iou\", \"f1\", \"precision\", \"recall\")}\n",
    "mean_time = []\n",
    "\n",
    "with tf.device(\"/CPU:0\"):\n",
    "\n",
    "    for i, (X, y, name) in enumerate(zip(batch_X, batch_y, valid_names)):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        raw = model(tf.expand_dims(X, 0), training=False)\n",
    "        raw = tf.squeeze(raw)\n",
    "\n",
    "        pred1 = utils.preprocess_raw_output(raw, 2, 2000)\n",
    "        pred2 = utils.preprocess_raw_output(pred1, 2, 0, max_seg_dist=30)\n",
    "        # pred2 = utils.preprocess_raw_output(pred2, 2, 0, max_seg_dist=20)\n",
    "        # pred2 = utils.preprocess_raw_output(pred2, 2, 0)\n",
    "\n",
    "        mean_time.append(time.time() - start)\n",
    "        # print(y.shape, pred.shape)\n",
    "\n",
    "        loss_value = loss_fn(tf.expand_dims(y, 0), tf.expand_dims(pred2, 0))\n",
    "        (\n",
    "            iou_value, tf_iou_value,\n",
    "            f1_score_value,\n",
    "            presicion_value, \n",
    "            recall_value\n",
    "        ) = metrics.calculate_metrics([y], [pred2])\n",
    "\n",
    "        val_metrics[\"loss\"].append(np.mean(loss_value))\n",
    "        val_metrics[\"iou\"].append(iou_value)\n",
    "        val_metrics[\"tf_iou\"].append(tf_iou_value)\n",
    "        val_metrics[\"f1\"].append(f1_score_value)\n",
    "        val_metrics[\"precision\"].append(presicion_value)\n",
    "        val_metrics[\"recall\"].append(recall_value)\n",
    "\n",
    "        # print(X[:, :, 0].shape, raw.shape, y.shape, pred.shape)\n",
    "        final_img = cv2.hconcat([\n",
    "            np.array(X[:, :, 0] * 255, dtype=np.uint8),\n",
    "            np.array(raw * 255, dtype=np.uint8),\n",
    "            np.array(y * 255, dtype=np.uint8),\n",
    "            np.array(pred1 * 255, dtype=np.uint8),\n",
    "            np.array(pred2 * 255, dtype=np.uint8)\n",
    "            # np.array(thresh)\n",
    "        ])\n",
    "\n",
    "        b_n, ext = os.path.splitext(name)\n",
    "        cv2.imwrite(\"pred_samples/{:.4f}_{}.png\".format(tf_iou_value, name), final_img)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7385195684432984"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1: valid loss 22.4344, tf_iou 0.8467, iou 0.6347, f1 0.8127, prec 0.6979, rec 0.6758\r"
     ]
    }
   ],
   "source": [
    "print_progress(\"valid\", val_metrics, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/cseadmin/Tigran/table_extractor/notebooks/../scripts/utils.py'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    name = \"2_44.bmp\"\n",
    "    X, y = utils.read_inf_sample([name], (512, 512))\n",
    "    raw = model(X, training=False)\n",
    "    X = tf.squeeze(X)\n",
    "    raw = tf.squeeze(raw)\n",
    "    y = tf.squeeze(y)\n",
    "\n",
    "    pred1 = utils.preprocess_raw_output(raw, 2, 100)\n",
    "    pred2 = utils.preprocess_raw_output(pred1, 2, 0, max_seg_dist=100)\n",
    "\n",
    "    final_img = cv2.hconcat([\n",
    "        np.array(X[:, :, 0] * 255, dtype=np.uint8),\n",
    "        np.array(raw * 255, dtype=np.uint8),\n",
    "        np.array(y * 255, dtype=np.uint8),\n",
    "        np.array(pred1 * 255, dtype=np.uint8),\n",
    "        np.array(pred2 * 255, dtype=np.uint8)\n",
    "        # np.array(thresh)\n",
    "    ])\n",
    "\n",
    "    cv2.imwrite(\"{:.4f}_{}.png\".format(tf_iou_value, name), final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a32f5061fcf236c4e6fcbf0f08e30b66d2a94d65fcc5ab372fe6f428f3c84fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
